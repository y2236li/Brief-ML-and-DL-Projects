{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from TryAroundModels import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle(X, y):\n",
    "    perm = np.random.permutation(len(X))\n",
    "    X = X[perm]\n",
    "    y = y[perm]\n",
    "    return X, y\n",
    "\n",
    "def load_imdb_dataset(path):\n",
    "    imdb_path = os.path.join(path, '')\n",
    "\n",
    "    # Load the dataset\n",
    "    train_texts = []\n",
    "    train_labels = []\n",
    "    test_texts = []\n",
    "    test_labels = []\n",
    "    for dset in ['train', 'test']:\n",
    "        for cat in ['pos', 'neg']:\n",
    "            dset_path = os.path.join(imdb_path, dset, cat)\n",
    "            for fname in sorted(os.listdir(dset_path)):\n",
    "                if fname.endswith('.txt'):\n",
    "                    with open(os.path.join(dset_path, fname)) as f:\n",
    "                        if dset == 'train': train_texts.append(f.read())\n",
    "                        else: test_texts.append(f.read())\n",
    "                    label = 0 if cat == 'neg' else 1\n",
    "                    if dset == 'train': train_labels.append(label)\n",
    "                    else: test_labels.append(label)\n",
    "\n",
    "    # Converting to np.array\n",
    "    train_texts = np.array(train_texts)\n",
    "    train_labels = np.array(train_labels)\n",
    "    test_texts = np.array(test_texts)\n",
    "    test_labels = np.array(test_labels)\n",
    "\n",
    "    # Shuffle the dataset\n",
    "    train_texts, train_labels = shuffle(train_texts, train_labels)\n",
    "    test_texts, test_labels = shuffle(test_texts, test_labels)\n",
    "\n",
    "    # Return the dataset\n",
    "    return train_texts, train_labels, test_texts, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts, train_labels, test_texts, test_labels = load_imdb_dataset(\"data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "NGRAM_RANGE = (1, 2)\n",
    "TOP_K = 20000\n",
    "TOKEN_MODE = 'word'\n",
    "MIN_DOC_FREQ = 2\n",
    "\n",
    "\n",
    "kwargs = {\n",
    "    'ngram_range' : NGRAM_RANGE,\n",
    "    'dtype' : 'int32',\n",
    "    'strip_accents' : 'unicode',\n",
    "    'decode_error' : 'replace',\n",
    "    'analyzer' : TOKEN_MODE,\n",
    "    'min_df' : MIN_DOC_FREQ,\n",
    "}\n",
    "\n",
    "# Learn Vocab from train texts and vectorize train and val sets\n",
    "tfidf_vectorizer = TfidfVectorizer(**kwargs)\n",
    "X_tfidf_train = tfidf_vectorizer.fit_transform(train_texts)\n",
    "X_tfidf_test = tfidf_vectorizer.transform(test_texts)\n",
    "\n",
    "selector = SelectKBest(f_classif, k=min(TOP_K, X_tfidf_train.shape[1]))\n",
    "selector.fit(X_tfidf_train, train_labels)\n",
    "X_selected_tfidf_train = selector.transform(X_tfidf_train).astype('float32')\n",
    "X_selected_tfidf_test = selector.transform(X_tfidf_test).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TryAroundModel_LG ['TryAroundModel_LG', 'TryAroundModel_NB', 'TryAroundModel_RF', 'TryAroundModel_GBM', 'TryAroundModel_NBSVM', 'TryAroundModel_MPLNN', 'TryAroundModel_LSTM', 'TryAroundModel_FB_LSTM', 'TryAroundModel_CNN', 'TryAroundModel']\n",
      "Logistic Regression -- Accuracy:  0.88356\n",
      "TryAroundModel_NB ['TryAroundModel_LG', 'TryAroundModel_NB', 'TryAroundModel_RF', 'TryAroundModel_GBM', 'TryAroundModel_NBSVM', 'TryAroundModel_MPLNN', 'TryAroundModel_LSTM', 'TryAroundModel_FB_LSTM', 'TryAroundModel_CNN', 'TryAroundModel']\n",
      "Multinomial Naive Bayes -- Accuracy:  0.859\n",
      "TryAroundModel_RF ['TryAroundModel_LG', 'TryAroundModel_NB', 'TryAroundModel_RF', 'TryAroundModel_GBM', 'TryAroundModel_NBSVM', 'TryAroundModel_MPLNN', 'TryAroundModel_LSTM', 'TryAroundModel_FB_LSTM', 'TryAroundModel_CNN', 'TryAroundModel']\n",
      "Random Forest -- Accuracy:  0.82364\n",
      "TryAroundModel_GBM ['TryAroundModel_LG', 'TryAroundModel_NB', 'TryAroundModel_RF', 'TryAroundModel_GBM', 'TryAroundModel_NBSVM', 'TryAroundModel_MPLNN', 'TryAroundModel_LSTM', 'TryAroundModel_FB_LSTM', 'TryAroundModel_CNN', 'TryAroundModel']\n",
      "Gradient Boosting Machine -- Accuracy:  0.70032\n",
      "TryAroundModel_NBSVM ['TryAroundModel_LG', 'TryAroundModel_NB', 'TryAroundModel_RF', 'TryAroundModel_GBM', 'TryAroundModel_NBSVM', 'TryAroundModel_MPLNN', 'TryAroundModel_LSTM', 'TryAroundModel_FB_LSTM', 'TryAroundModel_CNN', 'TryAroundModel']\n",
      "Naive Bayes SVM -- Accuracy:  0.86632\n",
      "TryAroundModel_MPLNN ['TryAroundModel_LG', 'TryAroundModel_NB', 'TryAroundModel_RF', 'TryAroundModel_GBM', 'TryAroundModel_NBSVM', 'TryAroundModel_MPLNN', 'TryAroundModel_LSTM', 'TryAroundModel_FB_LSTM', 'TryAroundModel_CNN', 'TryAroundModel']\n",
      "25000/25000 [==============================] - 384s 15ms/sample - loss: 0.2251\n",
      "Multilayer Perceptron Neural Network(MLP) -- Accuracy:  0.89868\n",
      "TryAroundModel_LSTM ['TryAroundModel_LG', 'TryAroundModel_NB', 'TryAroundModel_RF', 'TryAroundModel_GBM', 'TryAroundModel_NBSVM', 'TryAroundModel_MPLNN', 'TryAroundModel_LSTM', 'TryAroundModel_FB_LSTM', 'TryAroundModel_CNN', 'TryAroundModel']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/keras_preprocessing/text.py:178: UserWarning: The `nb_words` argument in `Tokenizer` has been renamed `num_words`.\n",
      "  warnings.warn('The `nb_words` argument in `Tokenizer` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 541s 22ms/sample - loss: 0.5303 - categorical_accuracy: 0.7326\n",
      "25000/25000 [==============================] - 90s 4ms/sample - loss: 0.3663 - categorical_accuracy: 0.8494\n",
      "LSTM Neural Network -- Accuracy:  0.84944\n",
      "TryAroundModel_FB_LSTM ['TryAroundModel_LG', 'TryAroundModel_NB', 'TryAroundModel_RF', 'TryAroundModel_GBM', 'TryAroundModel_NBSVM', 'TryAroundModel_MPLNN', 'TryAroundModel_LSTM', 'TryAroundModel_FB_LSTM', 'TryAroundModel_CNN', 'TryAroundModel']\n",
      "25000/25000 [==============================] - 3010s 120ms/sample - loss: 0.5074 - categorical_accuracy: 0.7521\n",
      "25000/25000 [==============================] - 489s 20ms/sample - loss: 0.5181 - categorical_accuracy: 0.7551\n",
      "Forward and Backward LSTM Neural Netword -- Accuracy:  0.75512\n",
      "TryAroundModel_CNN ['TryAroundModel_LG', 'TryAroundModel_NB', 'TryAroundModel_RF', 'TryAroundModel_GBM', 'TryAroundModel_NBSVM', 'TryAroundModel_MPLNN', 'TryAroundModel_LSTM', 'TryAroundModel_FB_LSTM', 'TryAroundModel_CNN', 'TryAroundModel']\n",
      "25000/25000 [==============================] - 117s 5ms/sample - loss: 0.3680 - categorical_accuracy: 0.8268\n",
      "25000/25000 [==============================] - 32s 1ms/sample - loss: 0.2904 - categorical_accuracy: 0.8771\n",
      "Convolutional Neural Network -- Accuracy:  0.87708\n",
      "TryAroundModel ['TryAroundModel_LG', 'TryAroundModel_NB', 'TryAroundModel_RF', 'TryAroundModel_GBM', 'TryAroundModel_NBSVM', 'TryAroundModel_MPLNN', 'TryAroundModel_LSTM', 'TryAroundModel_FB_LSTM', 'TryAroundModel_CNN', 'TryAroundModel']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Multilayer Perceptron Neural Network(MLP)', 0.89868),\n",
       " ('Logistic Regression', 0.88356),\n",
       " ('Convolutional Neural Network', 0.87708),\n",
       " ('Naive Bayes SVM', 0.86632),\n",
       " ('Multinomial Naive Bayes', 0.859),\n",
       " ('LSTM Neural Network', 0.84944),\n",
       " ('Random Forest', 0.82364),\n",
       " ('Forward and Backward LSTM Neural Netword', 0.75512),\n",
       " ('Gradient Boosting Machine', 0.70032)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def TryAroundModel(X_train, X_test, Y_train, Y_test, X_raw_text_train = None, X_raw_text_test = None, Models = None):\n",
    "    if Models is None:\n",
    "        Models = []\n",
    "        for i in np.nonzero([re.match(\"TryAroundModel\", x) for x in globals().keys()])[0]:\n",
    "            Models.append(list(globals().keys())[i])\n",
    "    \n",
    "    accuracy_list = []\n",
    "    processed_arg = [X_train, X_test, Y_train, Y_test]\n",
    "    \n",
    "    for m in Models:\n",
    "        print(m, Models)\n",
    "        if m == \"TryAroundModel_LG\":\n",
    "            accuracy_list.append(TryAroundModel_LG(*processed_arg))\n",
    "        elif m == \"TryAroundModel_NB\":\n",
    "            accuracy_list.append(TryAroundModel_NB(*processed_arg))\n",
    "        elif m == \"TryAroundModel_NBSVM\":\n",
    "            accuracy_list.append(TryAroundModel_NBSVM(*processed_arg))\n",
    "        elif m == \"TryAroundModel_RF\":\n",
    "            accuracy_list.append(TryAroundModel_RF(*processed_arg))\n",
    "        elif m == \"TryAroundModel_GBM\":\n",
    "            accuracy_list.append(TryAroundModel_GBM(*processed_arg))\n",
    "        elif m == \"TryAroundModel_MPLNN\":\n",
    "            accuracy_list.append(TryAroundModel_MPLNN(*processed_arg))\n",
    "\n",
    "        if X_raw_text_train is not None and X_raw_text_test is not None:\n",
    "\n",
    "            raw_arg = [X_raw_text_train, X_raw_text_test, Y_train, Y_test]\n",
    "            if m == \"TryAroundModel_CNN\":\n",
    "                accuracy_list.append(TryAroundModel_CNN(*raw_arg))\n",
    "            elif m == \"TryAroundModel_LSTM\":\n",
    "                accuracy_list.append(TryAroundModel_LSTM(*raw_arg))\n",
    "            elif m == \"TryAroundModel_FB_LSTM\":\n",
    "                accuracy_list.append(TryAroundModel_FB_LSTM(*raw_arg))\n",
    "        \n",
    "    return sorted(accuracy_list, key = lambda x: x[1], reverse = True)\n",
    "\n",
    "\n",
    "accuracy_list = TryAroundModel(X_selected_tfidf_train, X_selected_tfidf_test, train_labels,\n",
    "                               test_labels, train_texts, test_texts)\n",
    "accuracy_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Multilayer Perceptron Neural Network(MLP)</td>\n",
       "      <td>0.89868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.88356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Convolutional Neural Network</td>\n",
       "      <td>0.87708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Naive Bayes SVM</td>\n",
       "      <td>0.86632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Multinomial Naive Bayes</td>\n",
       "      <td>0.85900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LSTM Neural Network</td>\n",
       "      <td>0.84944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.82364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Forward and Backward LSTM Neural Netword</td>\n",
       "      <td>0.75512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Gradient Boosting Machine</td>\n",
       "      <td>0.70032</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           0        1\n",
       "0  Multilayer Perceptron Neural Network(MLP)  0.89868\n",
       "1                        Logistic Regression  0.88356\n",
       "2               Convolutional Neural Network  0.87708\n",
       "3                            Naive Bayes SVM  0.86632\n",
       "4                    Multinomial Naive Bayes  0.85900\n",
       "5                        LSTM Neural Network  0.84944\n",
       "6                              Random Forest  0.82364\n",
       "7   Forward and Backward LSTM Neural Netword  0.75512\n",
       "8                  Gradient Boosting Machine  0.70032"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(accuracy_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_list_old = accuracy_list.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0b0'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0b0\n",
      "0b11\n",
      "-0b1\n",
      "0b11\n",
      "0b0 \n",
      "\n",
      "0b10\n",
      "0b1\n",
      "-0b1\n",
      "0b1\n",
      "0b10 \n",
      "\n",
      "0b11\n",
      "0b10\n",
      "-0b11\n",
      "0b0\n",
      "0b1 \n",
      "\n",
      "0b1\n",
      "0b100\n",
      "-0b1\n",
      "0b100\n",
      "0b1 \n",
      "\n",
      "0b101\n",
      "0b1\n",
      "-0b10\n",
      "0b0\n",
      "0b100 \n",
      "\n",
      "0b100\n",
      "0b110\n",
      "-0b101\n",
      "0b10\n",
      "0b0 \n",
      "\n",
      "0b0\n",
      "0b110\n",
      "-0b1\n",
      "0b110\n",
      "0b0 \n",
      "\n",
      "The element with single occurrence is  6\n"
     ]
    }
   ],
   "source": [
    "# Python3 code to find the element that \n",
    "# appears once \n",
    "\n",
    "def getSingle(arr, n): \n",
    "\tones = 0\n",
    "\ttwos = 0\n",
    "\t\n",
    "\tfor i in range(n): \n",
    "\t\t# one & arr[i]\" gives the bits that \n",
    "\t\t# are there in both 'ones' and new \n",
    "\t\t# element from arr[]. We add these \n",
    "\t\t# bits to 'twos' using bitwise OR \n",
    "\t\ttwos = twos | (ones & arr[i]) \n",
    "\t\tprint(bin(twos))\n",
    "\t\t\n",
    "\t\t# one & arr[i]\" gives the bits that \n",
    "\t\t# are there in both 'ones' and new \n",
    "\t\t# element from arr[]. We add these \n",
    "\t\t# bits to 'twos' using bitwise OR \n",
    "\t\tones = ones ^ arr[i] \n",
    "\t\tprint(bin(ones))\n",
    "\t\t\n",
    "\t\t# The common bits are those bits \n",
    "\t\t# which appear third time. So these \n",
    "\t\t# bits should not be there in both \n",
    "\t\t# 'ones' and 'twos'. common_bit_mask \n",
    "\t\t# contains all these bits as 0, so \n",
    "\t\t# that the bits can be removed from \n",
    "\t\t# 'ones' and 'twos' \n",
    "\t\tcommon_bit_mask = ~(ones & twos) \n",
    "\t\tprint(bin(common_bit_mask))\n",
    "\t\t\n",
    "\t\t# Remove common bits (the bits that \n",
    "\t\t# appear third time) from 'ones' \n",
    "\t\tones &= common_bit_mask \n",
    "\t\tprint(bin(ones))\n",
    "\t\t\n",
    "\t\t# Remove common bits (the bits that \n",
    "\t\t# appear third time) from 'twos' \n",
    "\t\ttwos &= common_bit_mask \n",
    "\t\tprint(bin(twos), '\\n')\n",
    "\treturn ones \n",
    "\t\n",
    "# driver code \n",
    "arr = [3, 2, 3, 4, 5, 6, 4] \n",
    "n = len(arr) \n",
    "print(\"The element with single occurrence is \", \n",
    "\t\tgetSingle(arr, n)) \n",
    "\n",
    "# This code is contributed by \"Abhishek Sharma 44\" \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
